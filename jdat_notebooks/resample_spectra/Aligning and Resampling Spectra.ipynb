{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Draft: Aligning and Resampling Spectra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Imports\n",
    "Describe the libraries we're using here. If there's something unusual, explain what the library is, and why we need it.\n",
    "- *numpy* to handle array functions\n",
    "- *astropy.io fits* for accessing FITS files\n",
    "- *astropy.table Table* for creating tidy tables of the data\n",
    "- *matplotlib.pyplot* for plotting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from specutils import Spectrum1d\n",
    "from specutils import manipulation\n",
    "from astropy.wcs.utils import pixel_to_pixel\n",
    "from astropy.modeling import models, fitting\n",
    "from astropy.convolution import convolve_fft\n",
    "import astropy.units as u\n",
    "from scipy.interpolate import interp1d\n",
    "from jdaviz import SpecViz\n",
    "from webbpsf import NIRSpec, display_psf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sections:\n",
    " - Use specviz to identify good regions for fitting\n",
    " - Same instrument mode (dithers, etc.)\n",
    " - Same instrument, different modes (filters/grisms)\n",
    " - Different instruments (maybe?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction\n",
    "Write a short introduction explaining the purpose of the notebook. Link to any background materials/resources that may be useful to the reader to provide additional context.\n",
    "\n",
    "### Defining terms\n",
    "Be sure to define any terms/common acronyms at the end of your introduction that your audience may not know. If you're using some kind of domain-specific astronomical symbol or unusual mathematical concept, make sure you define it (e.g. in its mathematical form) and link to any definitions (literature/Wikipedia etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading data\n",
    "Need example data for this, with some variety for the different tools:\n",
    "1. Reference spectrum\n",
    "2. Same configuration as spectrum 1 (different dither?)\n",
    "3. Same instrument, different configuration as spectrum 1.\n",
    "4. Different instrument as spectrum 1.\n",
    "\n",
    "Each spectra then stored as `specutils.Spectrum1D`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where possible (if the code supports it): use code examples that use Jupyter to show what's in the data. For example, if you are showing an object such as a Table, display a preview of the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yourProd[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the products\n",
    "Observations.download_products(yourProd, mrp_only=False, cache=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File information\n",
    "\n",
    "Explain pertinent details about the file you've just downloaded. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling & Aligning Toolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use specviz to identify good regions for fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specviz = SpecViz()\n",
    "specviz.app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specviz.load_spectrum(spec1)\n",
    "specviz.load_spectrum(spec2)\n",
    "specviz.load_spectrum(spec3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining spectra from the same instrument configuration\n",
    "\n",
    "I.e., different dithers. Don't need to convolve because the PSF is the same. \n",
    "\n",
    "We're going to skip aligning the spectra via individual lines because we may not have enough signal before combining to be able to identify them.\n",
    "\n",
    "1. Do everything with specutils (via WCS)\n",
    "2. Do it by hand\n",
    "    1. align spectra via fitting\n",
    "    2. Resample & combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral registration, resampling, & combination via specutils\n",
    "# --------------------------------------------------------------\n",
    "# This is very straightforward, and is the recommended method in general.\n",
    "# Since we have WCS data for both, we can use a resampler from\n",
    "# specutils.manipulation to do the heavy lifting.\n",
    "\n",
    "fluxcon = manipulation.FluxConservingResampler()\n",
    "ref_dispersion_grid = spec1.spectral_axis\n",
    "spec2_reg_su = fluxcon(spec2, ref_dispersion_grid)\n",
    "\n",
    "#plot spec1, spec2 before, spec2 after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral registration via fitting\n",
    "# ---------------------------------\n",
    "# What we want is a composite model which transforms the original pixel coordinates\n",
    "# to registered coordinates (as pixel_to_pixel above). Since we're not identifying\n",
    "# individual spectral features, we have to use astropy.modeling in an unusual way.\n",
    "\n",
    "# We'll assume that the transformation is a 3rd-degree polynomial for this example,\n",
    "# but different datasets may require different functions. We define a custom model\n",
    "# that takes the flux from spectra 2 and resamples it onto the grid of spectra 1,\n",
    "# using our polynomial coefficients for the pixel transformation. (This is a preview\n",
    "# of the next subsection, but here we're not worrying about flux conservation.)\n",
    "\n",
    "# We want to fit to a (median-)normalized spectrum, since we're just looking to fit\n",
    "# to general shape and features. For a better fit, use specutils to identify good\n",
    "# regions for fitting in the previous section.\n",
    "\n",
    "norm1 = spec1.flux / np.abs(np.median(spec1.flux))\n",
    "norm2 = spec2.flux / np.abs(np.median(spec2.flux))\n",
    "\n",
    "@models.custom_model\n",
    "def pixel_transform(px, c0=0., c1=1., c2=0., c3=0.):\n",
    "    new_px = np.zeros_like(px) + c0.\n",
    "    new_px += c1 * px\n",
    "    new_px += c2 * px * px\n",
    "    new_px += c3 * px * px * px\n",
    "    resampled = interp1d(new_px, norm2)(pix1)\n",
    "    return resampled\n",
    "\n",
    "fitter = fitting.LevMarLSQFitter() #nonlinear\n",
    "pix2_reg_fit = fitter(pixel_transform, pix2_original, norm1)\n",
    "\n",
    "#plot spec1, spec2 before, spec2 after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample & Combine Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample & Combine\n",
    "# ------------------\n",
    "\n",
    "\n",
    "# options - use fluxcon (in which case why aren't we just\n",
    "# using specutils for everything? maybe we don't have WCS?)\n",
    "# or roll our own interpolator (in which case we're reinventing\n",
    "# the wheel...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching PSFs\n",
    "\n",
    "Used for combining spectra from the same instrument, different modes. Once we have matching PSFs, then we can use the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure WebbPSF works\n",
    "try:\n",
    "    instrument = NIRSpec()\n",
    "except OSError:\n",
    "    # assume that WebbPSF data files have not been downloaded\n",
    "    import tarfile, sys\n",
    "    print(\"Downloading WebbPSF data files.\")\n",
    "    webb_url = \"https://stsci.box.com/shared/static/qcptcokkbx7fgi3c00w2732yezkxzb99.gz\"\n",
    "    webb_file = os.path.join('.', \"webbpsf-data-0.9.0.tar.gz\")\n",
    "    urllib.request.urlretrieve(webb_url, webb_file)\n",
    "    print(\"Extracting into ./webbpsf-data ...\")\n",
    "    tar = tarfile.open(webb_file)\n",
    "    tar.extractall()\n",
    "    tar.close()\n",
    "    os.environ[\"WEBBPSF_PATH\"] = os.path.join(\".\",\"webbpsf-data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Developer note:** this section is only really useful if NIRSpec spectral science filters are implemented in WebbPSF... and we really need to use WebbPSF since the NIRSpec PSF is complicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a convolution kernel\n",
    "# ---------------------------\n",
    "# We want to smooth the higher-resolution spectrum to match the lower resolution.\n",
    "# We can make use of Fourier space for this. We'll assume that the reference spectrum\n",
    "# (spec1) has the lower resolution.\n",
    "\n",
    "# Luckily, making just two monochromatic kernels with WebbPSF is relatively fast.\n",
    "\n",
    "instrument1, instrument3 = NIRSpec(), NIRSpec()\n",
    "# Note that currently only TA filters are supported.\n",
    "instrument1.filter = model1.meta.filter\n",
    "instrument3.filter = model3.meta.filter\n",
    "mono_wave1 = np.median(spec1.spectral_axis).to(u.m) #WebbPSF requires wavelength in meters\n",
    "mono_wave3 = np.median(spec3.spectral_axis).to(u.m)\n",
    "\n",
    "# Since we don't know the original 2D FOV, we'll just use the default and coadd.\n",
    "mono_psf1 = instrument.calc_psf(monochromatic=mono_wave1).sum(axis=0)\n",
    "mono_psf3 = instrument.calc_psf(monochromatic=mono_wave3).sum(axis=0)\n",
    "\n",
    "# Now we combine them in Fourier space...\n",
    "fpsf1 = np.fft.fft(mono_psf1)\n",
    "fpsf3 = np.fft.fft(mono_psf3)\n",
    "kernel = np.fft.ifft(fpsf1 / fpsf3)\n",
    "\n",
    "# ...and convolve with spectrum 3\n",
    "# Note that there are many options for convolve_fft, particularly in how\n",
    "# it deals with nan values. Check the documentation for the best configuration\n",
    "# for a particular dataset.\n",
    "smoothed_spec3 = convolve_fft(spec3.flux, kernel)\n",
    "\n",
    "# plot initial specs, smoothed spec for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Account for wavelength-varying PSF. \n",
    "# -----------------------------------\n",
    "# We can generate psfs with WebbPSF as per the optimal extraction\n",
    "# notebook (and PSF matching from the previous step).\n",
    "\n",
    "# adapted from opt extract notebook\n",
    "wave1 = spec1.spectral_axis.to(u.m)\n",
    "wave3 = spec3.spectral_axis.to(u.m)\n",
    "nwave1, nwave3 = wave1.size, wave3.size\n",
    "psf_wave1 = np.linspace(wave1[0], wave1[-1], num=10)\n",
    "psf_wave3 = np.linspace(wave3[0], wave3[-1], num=10)\n",
    "cube1_hdul = instrument.calc_datacube(psf_wave1) #the output is a HDUList\n",
    "cube3_hdul = instrument.calc_datacube(psf_wave3)\n",
    "psf_cube1, psf_cube3 = cube1_hdul[1].data, cube3_hdul[1].data\n",
    "psf_x = psf_y = np.arange(48)\n",
    "out_x, out_y = np.meshgrid(psf_x, psf_y, indexing='ij')\n",
    "interpolator1 = RegularGridInterpolator((psf_wave1, psf_x, psf_y), psf_cube1, method='linear')\n",
    "interpolator3 = RegularGridInterpolator((psf_wave3, psf_x, psf_y), psf_cube3, method='linear')\n",
    "interp_psf1 = interpolator1((wave1, out_x, out_y)) # grab both PSFs at the spec3 wavelength locations\n",
    "interp_psf3 = interpolator3((wave1, out_x, out_y)) # so we can combine them as per the previous step\n",
    "\n",
    "var_kernel = np.zeros_like(interp_psf3)\n",
    "for i, (w1, w3) in enumerate(zip(interp_psf1, interp_psf3)):\n",
    "    fpsf1 = np.fft.fft2(w1)\n",
    "    fpsf3 = np.fft.fft2(w3)\n",
    "    k = np.fft.ifft2(fpsf1 / fpsf3)\n",
    "    var_kernel[i] = k\n",
    "\n",
    "var_kernel = var_kernel.sum(axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we convolve with the spatially-varying kernel by\n",
    "# iterating over each spectral flux element, multiplying\n",
    "# by the kernel at that wavelength, and adding it to the\n",
    "# appropriate bins in the smoothed spectrum array.\n",
    "\n",
    "dy = psf_y - psf_y[psf_y.size//2] #offsets along the dispersion axis\n",
    "\n",
    "var_smoothed_spec3 = np.zeros_like(spec3.flux)\n",
    "for i, spel in enumerate(spec3.flux):\n",
    "    window = i + dy\n",
    "    in_range = (window >= 0) & (window < nwave3)\n",
    "    vkern = var_kernel[i, psf_y[in_range]]\n",
    "    var_smoothed_spec3[window[in_range]] += spel * vkern\n",
    "    \n",
    "# plot initial specs, smoothed spec, non-varying smoothed spec for comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Actually writing this will require some example data... but it'll be fast because we're basically just copy/pasting from above.*\n",
    "\n",
    "1. Identify regions\n",
    "2. Spectral registration\n",
    "3. Match PSFs\n",
    "4. Resample & combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "Most notebooks are trying to convey _some_ information to their reader. It's often a good idea, if possible, to include in the notebook something where there is not an included answer so that the reader can cement in their mind how whatever it is they were supposed to learn from that notebook. If you do have exercise(s), be sure to leave a blank code cell underneath to show the user that it's meant for them to try it out right there. You may also want to include a \"solutions\" notebook next to your main notebook for the user to look at after they have finished their attempt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aditional Resources\n",
    "While this isn't always necessary, sometimes you want to provide some more resources for the reader who wants to learn something beyond what's in the notebook. Sometimes these don't exist, but if they do, it's good to put them at the end to give the reader somewhere else to go. Usually a list of links using markdown bullet-plus-link format is appropriate:\n",
    "\n",
    "- [MAST API](https://mast.stsci.edu/api/v0/index.html)\n",
    "- [Kepler Archive Page (MAST)](https://archive.stsci.edu/kepler/)\n",
    "- [Kepler Archive Manual](https://archive.stsci.edu/kepler/manuals/archive_manual.pdf)\n",
    "- [Exo.MAST website](https://exo.mast.stsci.edu/exo/ExoMast/html/exomast.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## About this notebook\n",
    "Let the world know who the author of this great notebook is! If possible/appropriate, include a contact email address for users who might need support (e.g. archive@stsci.edu)\n",
    "\n",
    "**Author:** Jessie Blogs, Archive Scientist.  \n",
    "**Updated On:** YYYY-MM-DD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#top)\n",
    "<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/spacetelescope/notebooks/master/assets/stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"Space Telescope Logo\" width=\"200px\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
